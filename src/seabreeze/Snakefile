import pandas as pd

path_to_data_csv=config["data"]
df = pd.read_csv(path_to_data_csv)

list_of_ancestors = df['ancestor'].tolist()
list_of_assemblies = df['assembly'].tolist()

for ancestor in list_of_ancestors:
    if not(ancestor in list_of_assemblies):
        raise ValueError(f"Ancestor genome {ancestor} needs a self-to-self comparison. Please append this line to data.csv: {ancestor},{ancestor}")

# this dictionary maps the subject to its query
assembly_to_ancestor_dict = dict(zip(df['assembly'], df['ancestor']))

# ---- ONE (TWO, TECHNICALLY) RULE TO RULE THEM ALL .. ----

rule run_all_masked:
    input:
        genome_sizes = "04_rename_genome/genome_size_stats.csv",
        is_csv_files = expand("05_isescan_tables/{sample}.csv", sample=df['assembly'].tolist()), # we only want the csv file, so that's the target of this rule is that.
        clean_synteny_plots = expand("07_syri_output/masked/{sample}/{sample}_clean.plot.pdf", sample=df['assembly'].tolist()),
        ori_dif_coords = "04_rename_genome/ori_dif_coords.csv",
        ori_dif_coords_reindexed = "08_reindex_genome_oric/ori_dif_coords.csv",
        replichore_arms = "08_reindex_genome_oric/replichore_arms.csv",
        inversion_replichores = expand("11_annotated_boundaries/masked/{sample}_inversion_classification.csv", sample=df['assembly'].tolist()),
        inversion_table = "11_annotated_boundaries/masked/inversion_mechanism.csv",
        deletion_table = "11_annotated_boundaries/masked/deletion_mechanism.csv",
        gd = expand("12_genome_diff_tables/gd/masked/{sample}.gd",sample=df['assembly'].tolist()),
        html = expand("12_genome_diff_tables/html/masked/{sample}.html",sample=df['assembly'].tolist())

rule run_all_unmasked:
    input:
        genome_sizes = "04_rename_genome/genome_size_stats.csv",
        is_csv_files = expand("05_isescan_tables/{sample}.csv", sample=df['assembly'].tolist()), # we only want the csv file, so that's the target of this rule is that.
        clean_synteny_plots = expand("07_syri_output/unmasked/{sample}/{sample}_clean.plot.pdf", sample=df['assembly'].tolist()),
        ori_dif_coords = "04_rename_genome/ori_dif_coords.csv",
        ori_dif_coords_reindexed = "08_reindex_genome_oric/ori_dif_coords.csv",
        replichore_arms = "08_reindex_genome_oric/replichore_arms.csv",
        inversion_replichores = expand("11_annotated_boundaries/unmasked/{sample}_inversion_classification.csv", sample=df['assembly'].tolist()),
        inversion_table = "11_annotated_boundaries/unmasked/inversion_mechanism.csv",
        deletion_table = "11_annotated_boundaries/unmasked/deletion_mechanism.csv",
        gd = expand("12_genome_diff_tables/gd/unmasked/{sample}.gd",sample=df['assembly'].tolist()),
        html = expand("12_genome_diff_tables/html/unmasked/{sample}.html",sample=df['assembly'].tolist())

# ---- TARGET RULES ----

rule analyse_genome_sizes:
    input:
        genome_sizes = "04_rename_genome/genome_size_stats.csv"

rule predict_IS_elements:
    input:
        is_csv_files = expand("05_isescan_tables/{sample}.csv", sample=df['assembly'].tolist()) # we only want the csv file, so that's the target of this rule is that.

rule predict_structural_variants_unmasked:
    input:
        clean_synteny_plots = expand("07_syri_output/unmasked/{sample}/{sample}_clean.plot.pdf", sample=df['assembly'].tolist()),

rule predict_structural_variants_masked:
    input:
        clean_synteny_plots = expand("07_syri_output/masked/{sample}/{sample}_clean.plot.pdf", sample=df['assembly'].tolist()),

rule predict_replichore_balance_unmasked:
    input:
        ori_dif_coords = "04_rename_genome/ori_dif_coords.csv",
        ori_dif_coords_reindexed = "08_reindex_genome_oric/ori_dif_coords.csv",
        replichore_arms = "08_reindex_genome_oric/replichore_arms.csv",
        inversion_replichores = expand("11_annotated_boundaries/unmasked/{sample}_inversion_classification.csv", sample=df['assembly'].tolist()),

rule predict_replichore_balance_masked:
    input:
        ori_dif_coords = "04_rename_genome/ori_dif_coords.csv",
        ori_dif_coords_reindexed = "08_reindex_genome_oric/ori_dif_coords.csv",
        replichore_arms = "08_reindex_genome_oric/replichore_arms.csv",
        inversion_replichores = expand("11_annotated_boundaries/masked/{sample}_inversion_classification.csv", sample=df['assembly'].tolist()),

rule predict_SV_mechanism_unmasked:
    input:
        inversion_table = "11_annotated_boundaries/unmasked/inversion_mechanism.csv",
        deletion_table = "11_annotated_boundaries/unmasked/deletion_mechanism.csv",

rule predict_SV_mechanism_masked:
    input:
        inversion_table = "11_annotated_boundaries/masked/inversion_mechanism.csv",
        deletion_table = "11_annotated_boundaries/masked/deletion_mechanism.csv",


rule annotate_SV_regions_unmasked:
    input:
        gd = expand("12_genome_diff_tables/gd/unmasked/{sample}.gd",sample=df['assembly'].tolist()),
        html = expand("12_genome_diff_tables/html/unmasked/{sample}.html",sample=df['assembly'].tolist())


rule annotate_SV_regions_masked:
    input:
        gd = expand("12_genome_diff_tables/gd/masked/{sample}.gd",sample=df['assembly'].tolist()),
        html = expand("12_genome_diff_tables/html/masked/{sample}.html",sample=df['assembly'].tolist())


# ---- INDIVIDUAL RULES ----

# find unique bases at the start of the subject sequence to reindex the query sequence to

rule find_reindex_bases:
    conda:
        "{}/workflow/envs/biopython.yml".format(workflow.basedir)
    input:
        query_path = "02_genomes/{sample}.fasta", # path to the assembly
        subject_path = lambda wildcards: "02_genomes/{}.fasta".format(assembly_to_ancestor_dict[wildcards.sample]), # path to the assembly its being compared to
        script = "{}/find_reindex_bases.py".format(workflow.basedir)
    output:
        "03_reindex_genomes/reindex_bases_{sample}.txt"
    log:
        "logs/find_reindex_bases/{sample}.log"
    shell:
        '''
        {input.script} --subject {input.subject_path} --query {input.query_path} --output {output} > {log} 2>&1
        '''

#reindex the fasta files to a common sequence to make comparison easier

rule reindex_contigs:
    conda:
        "{}/workflow/envs/biopython.yml".format(workflow.basedir)
    input:
        fasta = "02_genomes/{sample}.fasta",
        bases = "03_reindex_genomes/reindex_bases_{sample}.txt",
        script = "{}/reindex_assembly.py".format(workflow.basedir)
    output:
       "03_reindex_genomes/{sample}.fasta"
    log:
        "logs/reindex_contigs/{sample}.log"
    shell:
       "{input.script} -b $(cat {input.bases})  -i {input.fasta} -o {output} -t fasta > {log} 2>&1"

# rename all the FASTA headers to "genome"
# this step is needed for SyRI which will only carry out variant calling for two sequence with the same header

rule rename_contigs:
    conda:
        "{}/workflow/envs/biopython.yml".format(workflow.basedir)
    input:
        data = "03_reindex_genomes/{sample}.fasta",
        script = "{}/rename_contigs.py".format(workflow.basedir)
    params:
        new_FASTA_header = "genome"
    output:
        "04_rename_genome/unmasked/{sample}.fasta"
    log:
        "logs/rename_contigs/{sample}.log"
    shell:
        "{input.script} --file {input.data}  --name {params.new_FASTA_header} --output {output} > {log} 2>&1"


rule compute_genome_stats:
    conda:
        "{}/workflow/envs/biopython.yml".format(workflow.basedir)
    input:
        data =  expand("04_rename_genome/unmasked/{sample}.fasta", sample=df['assembly'].tolist()),
        script = "{}/fasta_stats.py".format(workflow.basedir),
        csv_file = config['data']
    params:
        folder = "04_rename_genome/unmasked/"
    output:
        genome_sizes = "04_rename_genome/genome_size_stats.csv"
    log:
        "logs/compute_genome_stats/compute_genome_stats.log"
    shell:
        "{input.script} --folder {params.folder} --data {input.csv_file} --output {output.genome_sizes} > {log} 2>&1"

# ISEScan takes the genome assemblies and returns several files. We only need to the csv file it generates

rule find_IS_elements:
    conda:
        "{}/workflow/envs/isescan.yml".format(workflow.basedir)
    input:
        "04_rename_genome/unmasked/{sample}.fasta"
    output:
        csv_files = "05_isescan_tables/{sample}.csv"
    threads:
        config['threads']
    log:
        "logs/find_IS_elements/{sample}.log"
    shell:
        """
        cp {input} ./{wildcards.sample}.fasta
        isescan.py --seqfile {wildcards.sample}.fasta --output 05_isescan_tables/{wildcards.sample} --nthread {threads} >> {log} 2>&1
        mv 05_isescan_tables/{wildcards.sample}/{wildcards.sample}.fasta.csv 05_isescan_tables/{wildcards.sample}.csv
        rm {wildcards.sample}.fasta
        """

rule mask_IS_elements:
    conda:
        "{}/workflow/envs/biopython.yml".format(workflow.basedir)
    input:
        genome = "04_rename_genome/unmasked/{sample}.fasta",
        is_table = "05_isescan_tables/{sample}.csv",
        script = "{}/mask_IS_elements.py".format(workflow.basedir)
    output:
        masked_genome = "04_rename_genome/masked/{sample}.fasta"
    log:
        "logs/mask_IS_elements/{sample}.log"
    shell:
        """
        {input.script} --genome {input.genome} --is_table {input.is_table} --output {output.masked_genome}  >> {log} 2>&1
        """

# align each assembly to its ancestor, then filter the alignments and convert from .delta to coords

rule align_genomes_nucmer_unmasked:
    conda:
        "{}/workflow/envs/mummer4.yml".format(workflow.basedir)
    input:
        query_path = "04_rename_genome/unmasked/{sample}.fasta", # path to the assembly
        subject_path = lambda wildcards: "04_rename_genome/unmasked/{}.fasta".format(assembly_to_ancestor_dict[wildcards.sample]) # path to the assembly of the ancestor its being >
    output:
        done = "06_nucmer_alignment/unmasked/{sample}/{sample}.done",
        delta = "06_nucmer_alignment/unmasked/{sample}/{sample}.delta",
        filtered = "06_nucmer_alignment/unmasked/{sample}/{sample}.filtered.delta",
        coords = "06_nucmer_alignment/unmasked/{sample}/{sample}.filtered.coords"
    params:
        seq_id_cutoff = "95",
        subject_name = lambda wildcards: "{}.fasta".format(assembly_to_ancestor_dict[wildcards.sample]), # just the name of the ancestor (does not include the .fasta extension)
        output_dir = "06_nucmer_alignment/unmasked/{sample}" # each assembly gets its own directory with the same name which stores the output of nucmer
    log:
        "logs/align_genomes_nucmer_unmasked/{sample}.log"

    shell:
        """
        mkdir -p {params.output_dir}
        cd {params.output_dir}
        touch ../../../{log}
        nucmer --maxmatch -c 100 -b 500 -l 50 -p {wildcards.sample} ../../../{input.subject_path} ../../../{input.query_path} > ../../../{log} 2>&1
        delta-filter -i {params.seq_id_cutoff} -l 100 {wildcards.sample}.delta > {wildcards.sample}.filtered.delta
        show-coords -THrd {wildcards.sample}.filtered.delta > {wildcards.sample}.filtered.coords
        touch {wildcards.sample}.done
        cd ../../../
        """

rule align_genomes_nucmer_masked:
    conda:
        "{}/workflow/envs/mummer4.yml".format(workflow.basedir)
    input:
        query_path = "04_rename_genome/masked/{sample}.fasta", # path to the assembly
        subject_path = lambda wildcards: "04_rename_genome/masked/{}.fasta".format(assembly_to_ancestor_dict[wildcards.sample]) # path to the assembly of the ancestor its being co>
    output:
        done = "06_nucmer_alignment/masked/{sample}/{sample}.done",
        delta = "06_nucmer_alignment/masked/{sample}/{sample}.delta",
        filtered = "06_nucmer_alignment/masked/{sample}/{sample}.filtered.delta",
        coords = "06_nucmer_alignment/masked/{sample}/{sample}.filtered.coords"
    params:
        seq_id_cutoff = "95",
        subject_name = lambda wildcards: "{}.fasta".format(assembly_to_ancestor_dict[wildcards.sample]), # just the name of the ancestor (does not include the .fasta extension)
        output_dir = "06_nucmer_alignment/masked/{sample}" # each assembly gets its own directory with the same name which stores the output of nucmer
    log:
        "logs/align_genomes_nucmer_masked/{sample}.log"
    # temporarily move both fasta files here because it's easier. delete when done. NO DO NOT DO THIS! CAUSES A BUG WHEN COMPARING A SEQUENCE TO ITSELF
    shell:
        """
        mkdir -p {params.output_dir}
        cd {params.output_dir}
        touch ../../../{log}
        nucmer --maxmatch -c 100 -b 500 -l 50 -p {wildcards.sample} ../../../{input.subject_path} ../../../{input.query_path} > ../../../{log} 2>&1
        delta-filter -i {params.seq_id_cutoff} -l 100 {wildcards.sample}.delta > {wildcards.sample}.filtered.delta
        show-coords -THrd {wildcards.sample}.filtered.delta > {wildcards.sample}.filtered.coords
        touch {wildcards.sample}.done
        cd ../../../
        """

# now call structural variants from the alignments

rule call_variants_syri_unmasked:
    conda:
        "{}/workflow/envs/syri.yml".format(workflow.basedir)
    input:
           filtered = "06_nucmer_alignment/unmasked/{sample}/{sample}.filtered.delta",
        query_path = "04_rename_genome/unmasked/{sample}.fasta", # path to the assembly
        subject_path = lambda wildcards: "04_rename_genome/unmasked/{}.fasta".format(assembly_to_ancestor_dict[wildcards.sample]), # path to the assembly of the ancestor its being>
        coords = "06_nucmer_alignment/unmasked/{sample}/{sample}.filtered.coords"
    output:
        done = "07_syri_output/unmasked/{sample}/{sample}.done",
        syri = "07_syri_output/unmasked/{sample}/{sample}.syri.out"
    params:
           output_dir = "07_syri_output/unmasked/{sample}", # each assembly gets its own directory with the same name which stores the output of nucmer
    log:
        "logs/call_variants_syri_unmasked/{sample}.log"
    shell:
           """
           mkdir -p {params.output_dir}
        cd {params.output_dir}
        touch ../../../{log}
        syri --nosnp -c ../../../{input.coords} -d ../../../{input.filtered} -r ../../../{input.subject_path} -q ../../../{input.query_path} --prefix {wildcards.sample} > ../../../{log} 2>&1
        mv {wildcards.sample}syri.out {wildcards.sample}.syri.out
        touch {wildcards.sample}.done
        rm {wildcards.sample}syri.log {wildcards.sample}syri.summary
        cd ../../../
        """

rule call_variants_syri_masked:
    conda:
           "{}/workflow/envs/syri.yml".format(workflow.basedir)
    input:
           filtered = "06_nucmer_alignment/masked/{sample}/{sample}.filtered.delta",
        query_path = "04_rename_genome/masked/{sample}.fasta", # path to the assembly
        subject_path = lambda wildcards: "04_rename_genome/masked/{}.fasta".format(assembly_to_ancestor_dict[wildcards.sample]), # path to the assembly of the ancestor its being c>
        coords = "06_nucmer_alignment/masked/{sample}/{sample}.filtered.coords"
    output:
           done = "07_syri_output/masked/{sample}/{sample}.done",
        syri = "07_syri_output/masked/{sample}/{sample}.syri.out"
    params:
           output_dir = "07_syri_output/masked/{sample}", # each assembly gets its own directory with the same name which stores the output of nucmer
    log:
        "logs/call_variants_syri_masked/{sample}.log"
    shell:
           """
           mkdir -p {params.output_dir}
        cd {params.output_dir}
        touch ../../../{log}
        syri --nosnp -c ../../../{input.coords} -d ../../../{input.filtered} -r ../../../{input.subject_path} -q ../../../{input.query_path} --prefix {wildcards.sample} > ../../../{log} 2>&1
        mv {wildcards.sample}syri.out {wildcards.sample}.syri.out
        touch {wildcards.sample}.done
        rm {wildcards.sample}syri.log {wildcards.sample}syri.summary
        cd ../../../
        """

rule generate_synteny_plot_unmasked:
    conda:
           "{}/workflow/envs/plotsr.yml".format(workflow.basedir)
    input:
           query_path = "04_rename_genome/unmasked/{sample}.fasta", # path to the assembly
        subject_path = lambda wildcards: "04_rename_genome/unmasked/{}.fasta".format(assembly_to_ancestor_dict[wildcards.sample]), # path to the assembly of the ancestor its being>
        syri = "07_syri_output/unmasked/{sample}/{sample}.syri.out",
        script = "{}/plotsr/plotsr-bin".format(workflow.basedir)
    output:
           genome_table = "07_syri_output/unmasked/{sample}/{sample}.genomes.tsv",
        plot = "07_syri_output/unmasked/{sample}/{sample}.plot.pdf"
    params:
           input_dir = "07_syri_output/unmasked/{sample}", #store the synteny plot in the same place as the syri files
        subject_name = lambda wildcards: "{}.fasta".format(assembly_to_ancestor_dict[wildcards.sample]) # just the name of the ancestor (does not include the .fasta extension)
    log:
        "logs/generate_synteny_plots_unmasked/{sample}.log"
    shell:
           """
           cd {params.input_dir}
        printf "#file\tname\ttags\n" > {wildcards.sample}.genomes.tsv
        printf "../../../{input.subject_path}\t{params.subject_name}\tlw:1.5\n" >> {wildcards.sample}.genomes.tsv
        printf "../../../{input.query_path}\t{wildcards.sample}\tlw:1.5" >>  {wildcards.sample}.genomes.tsv
        {input.script} -s 500 --genomes {wildcards.sample}.genomes.tsv --sr {wildcards.sample}.syri.out -H 5 -W 10 -o {wildcards.sample}.plot.pdf --lf {wildcards.sample}.log
        mv {wildcards.sample}.log ../../../{log}
        cd ../../..
        """


rule generate_synteny_plot_masked:
    conda:
           "{}/workflow/envs/plotsr.yml".format(workflow.basedir)
    input:
           query_path = "04_rename_genome/masked/{sample}.fasta", # path to the assembly
        subject_path = lambda wildcards: "04_rename_genome/masked/{}.fasta".format(assembly_to_ancestor_dict[wildcards.sample]), # path to the assembly of the ancestor its being c>
        syri = "07_syri_output/masked/{sample}/{sample}.syri.out",
        script = "{}/plotsr/plotsr-bin".format(workflow.basedir)
    output:
           genome_table = "07_syri_output/masked/{sample}/{sample}.genomes.tsv",
        plot = "07_syri_output/masked/{sample}/{sample}.plot.pdf"
    params:
           input_dir = "07_syri_output/masked/{sample}", #store the synteny plot in the same place as the syri files
        subject_name = lambda wildcards: "{}.fasta".format(assembly_to_ancestor_dict[wildcards.sample]) # just the name of the ancestor (does not include the .fasta extension)
    log:
        "logs/generate_synteny_plots_masked/{sample}.log"
    shell:
        """
        cd {params.input_dir}
        printf "#file\tname\ttags\n" > {wildcards.sample}.genomes.tsv
        printf "../../../{input.subject_path}\t{params.subject_name}\tlw:1.5\n" >> {wildcards.sample}.genomes.tsv
        printf "../../../{input.query_path}\t{wildcards.sample}\tlw:1.5" >>  {wildcards.sample}.genomes.tsv
        {input.script} -s 500 --genomes {wildcards.sample}.genomes.tsv --sr {wildcards.sample}.syri.out -H 5 -W 10 -o {wildcards.sample}.plot.pdf --lf {wildcards.sample}.log
        mv {wildcards.sample}.log ../../../{log}
        cd ../../..
        """

# now clean up the syri files to predict a minimal set of structural variants
rule clean_syri_output_unmasked:
    conda:
           "{}/workflow/envs/pandas.yml".format(workflow.basedir)
    input:
           syri = "07_syri_output/unmasked/{sample}/{sample}.syri.out",
        query_path = "05_isescan_tables/{sample}.csv", # path to the isescan file of the
        subject_path = lambda wildcards: "05_isescan_tables/{}.csv".format(assembly_to_ancestor_dict[wildcards.sample]) # path to the assembly of the ancestor its being compared to
    output:
           "07_syri_output/unmasked/{sample}/{sample}_clean.syri.out"
    params:
        # isescan_subject_path = expand("data/05_isescan_tables/{sample}.csv", sample=df['assembly'].tolist()), # listing this as an input triggers an InputExceptionError idk why
        # isescan_query = lambda wildcards: "{}.csv".format(assembly_to_ancestor_dict[wildcards.sample]), # just the name of the ancestor (does not include the .fasta extension)
        isescan_dir = "05_isescan_tables",
        input_dir = "07_syri_output/unmasked/{sample}",
        script = "{}/clean_syri.py".format(workflow.basedir)
    log:
        "logs/clean_syri_output_unmasked/{sample}.log"
    shell:
        """
           cd {params.input_dir}
        {params.script} --syri {wildcards.sample}.syri.out --isescan_query ../../../{input.query_path} --isescan_subject ../../../{input.subject_path} > ../../../{log} 2>&1
        cd ../../../
        """

# now clean up the syri files to predict a minimal set of structural variants
rule clean_syri_output_masked:
    conda:
           "{}/workflow/envs/pandas.yml".format(workflow.basedir)
    input:
           syri = "07_syri_output/masked/{sample}/{sample}.syri.out",
        query_path = "05_isescan_tables/{sample}.csv", # path to the isescan file of the
        subject_path = lambda wildcards: "05_isescan_tables/{}.csv".format(assembly_to_ancestor_dict[wildcards.sample]) # path to the assembly of the ancestor its being compared to
    output:
        "07_syri_output/masked/{sample}/{sample}_clean.syri.out"
    params:
        # isescan_subject_path = expand("05_isescan_tables/{sample}.csv", sample=df['assembly'].tolist()), # listing this as an input triggers an InputExceptionError idk why
        # isescan_query = lambda wildcards: "{}.csv".format(assembly_to_ancestor_dict[wildcards.sample]), # just the name of the ancestor (does not include the .fasta extension)
        isescan_dir = "05_isescan_tables",
        input_dir = "07_syri_output/masked/{sample}",
        script = "{}/clean_syri.py".format(workflow.basedir)
    log:
        "logs/clean_syri_output_masked/{sample}.log"
    shell:
           """
           cd {params.input_dir}
        {params.script} --syri {wildcards.sample}.syri.out --isescan_query ../../../{input.query_path} --isescan_subject ../../../{input.subject_path} >  ../../../{log} 2>&1
        cd ../../../
        """

# with the new clean syri file, generate a new plot
rule generate_synteny_plot_clean_unmasked:
    conda:
           "{}/workflow/envs/plotsr.yml".format(workflow.basedir)
    input:
           syri = "07_syri_output/unmasked/{sample}/{sample}_clean.syri.out",
        script = "{}/plotsr/plotsr-bin".format(workflow.basedir),
        genome_table = "07_syri_output/unmasked/{sample}/{sample}.genomes.tsv",
    output:
           "07_syri_output/unmasked/{sample}/{sample}_clean.plot.pdf"
    params:
           input_dir = "07_syri_output/unmasked/{sample}", #store the synteny plot in the same place as the syri files
        subject_name = lambda wildcards: "{}.fasta".format(assembly_to_ancestor_dict[wildcards.sample]) # just the name of the ancestor (does not include the .fasta extension)
    log:
        "logs/generate_synteny_plots_unmasked/{sample}_clean.log"
    shell:
           """
           cd {params.input_dir}
        {input.script} -s 500 --genomes {wildcards.sample}.genomes.tsv --sr {wildcards.sample}_clean.syri.out -H 5 -W 10 -o {wildcards.sample}_clean.plot.pdf --lf {wildcards.sample}_clean.log
        mv {wildcards.sample}_clean.log ../../../{log}
        cd ../../../
           """

rule generate_synteny_plot_clean_masked:
    conda:
           "{}/workflow/envs/plotsr.yml".format(workflow.basedir)
    input:
           syri = "07_syri_output/masked/{sample}/{sample}_clean.syri.out",
        script = "{}/plotsr/plotsr-bin".format(workflow.basedir),
        genome_table = "07_syri_output/masked/{sample}/{sample}.genomes.tsv",
    output:
           "07_syri_output/masked/{sample}/{sample}_clean.plot.pdf"
    params:
           input_dir = "07_syri_output/masked/{sample}", #store the synteny plot in the same place as the syri files
        subject_name = lambda wildcards: "{}.fasta".format(assembly_to_ancestor_dict[wildcards.sample]) # just the name of the ancestor (does not include the .fasta extension)
    log:
        "logs/generate_synteny_plots_masked/{sample}_clean.log"
    shell:
        """
           cd {params.input_dir}
        {input.script} -s 500 --genomes {wildcards.sample}.genomes.tsv --sr {wildcards.sample}_clean.syri.out -H 5 -W 10 -o {wildcards.sample}_clean.plot.pdf --lf {wildcards.sample}_clean.log
        mv {wildcards.sample}_clean.log ../../../{log}
        cd ../../..
        """

# generate a csv file with the ori and dif coords of the genomes in their original index
rule annotate_ori_dif_locations:
    conda:
        "{}/workflow/envs/biopython.yml".format(workflow.basedir)
    input:
        genomes = expand("04_rename_genome/unmasked/{sample}.fasta", sample=df['assembly'].tolist()), # you can't use wildcards here but you can use this expand functionality
        script = "{}/replichore_arms_analyse.py".format(workflow.basedir)
    output:
        ori_dif_coords = "04_rename_genome/ori_dif_coords.csv"
    params:
        data=config['data'],
        sequences=config['oridif'],
        folder = "04_rename_genome/unmasked/"
    log:
        "logs/annotate_ori_dif_locations/annotate_ori_dif_locations.log"
    shell:
        """
        {input.script} --genomes {params.folder} --data {params.data} --sequences {params.sequences} --output {output} --noarms > {log}  2>&1
        """

rule reindex_contigs_oric_unmasked:
    conda:
        "{}/workflow/envs/biopython.yml".format(workflow.basedir)
    input:
           genomes = expand("04_rename_genome/unmasked/{sample}.fasta", sample=df['assembly'].tolist()), # you can't use wildcards here but you can use this expand functionality
        script = "{}/reindex_assembly_batch.py".format(workflow.basedir)
    output:
           expand("08_reindex_genome_oric/unmasked/{sample}.fasta", sample=df['assembly'].tolist()), # you can't use wildcards here but you can use this expand functionality
    params:
           folder = "04_rename_genome/unmasked/",
        data = config['data'],
        sequences=config['oridif'],
        output = "08_reindex_genome_oric/unmasked"
    log:
        "logs/reindex_contigs_oric/unmasked/reindex_contigs_oric.log"
    shell:
           """
           {input.script} --folder {params.folder} --data {params.data} --sequences {params.sequences} --output {params.output} > {log} 2>&1
        """

rule reindex_contigs_oric_masked:
    conda:
           "{}/workflow/envs/biopython.yml".format(workflow.basedir)
    input:
           genomes = expand("04_rename_genome/masked/{sample}.fasta", sample=df['assembly'].tolist()), # you can't use wildcards here but you can use this expand functionality
        script = "{}/reindex_assembly_batch.py".format(workflow.basedir)
    output:
           expand("08_reindex_genome_oric/masked/{sample}.fasta", sample=df['assembly'].tolist()), # you can't use wildcards here but you can use this expand functionality
    params:
           folder = "04_rename_genome/masked/",
        data = config['data'],
        sequences= config['oridif'],
        output = "08_reindex_genome_oric/masked"
    log:
        "logs/reindex_contigs_oric/masked/reindex_contigs_oric.log"
    shell:
           """
           {input.script} --folder {params.folder} --data {params.data} --sequences {params.sequences} --output {params.output} > {log} 2>&1
        """

# generate a csv file with the oric and dif of the genomens reindexed to the ori and a csv file with lenths of the replichore arms of each clone

rule analyse_replichore_arms:
    conda:
        "{}/workflow/envs/biopython.yml".format(workflow.basedir)
    input:
           genomes = expand("08_reindex_genome_oric/unmasked/{sample}.fasta", sample=df['assembly'].tolist()), # you can't use wildcards here but you can use this expand functionality
        script = "{}/replichore_arms_analyse.py".format(workflow.basedir)
    output:
           ori_dif_coords = "08_reindex_genome_oric/ori_dif_coords.csv",
        replichore_balance = "08_reindex_genome_oric/replichore_arms.csv"
    params:
           folder = "08_reindex_genome_oric/unmasked",
        data = config['data'],
        sequences= config['oridif']
    log:
        "logs/analyse_replichore_arms/analyse_replichore_arms.log"
    shell:
           """
           {input.script} --genomes {params.folder} --data {params.data} --sequences {params.sequences} --output {output.ori_dif_coords} --noarms > {log} 2>&1
        {input.script} --genomes {params.folder} --data {params.data} --sequences {params.sequences} --output {output.replichore_balance}  >> {log} 2>&1
        """

# generate csv files which annotate the boundaries of the SVs
rule annotate_SV_boundaries_IS_unmasked:
    conda:
           "{}/workflow/envs/pandas.yml".format(workflow.basedir)
    input:
        syri = "07_syri_output/unmasked/{sample}/{sample}_clean.syri.out",
        assembly_IS_csv = "05_isescan_tables/{sample}.csv",
        ancestor_IS_csv = lambda wildcards: "05_isescan_tables/{}.csv".format(assembly_to_ancestor_dict[wildcards.sample]), # path to the csv file of the ancestor
        script = "{}/IS_SV_border.py".format(workflow.basedir)
    output:
           "11_annotated_boundaries/unmasked/{sample}_boundaries.csv"
    log:
        "logs/annotate_SV_boundaries_IS_unmasked/{sample}.log"
    shell:
           """
           mkdir -p 11_annotated_boundaries/unmasked
        cd 11_annotated_boundaries/unmasked
        {input.script} --ancestor ../../{input.ancestor_IS_csv} --evolved ../../{input.assembly_IS_csv} --syri ../../{input.syri} --output {wildcards.sample}_boundaries.csv > ../../{log} 2>&1
        cd ../../
        """

rule annotate_SV_boundaries_IS_masked:
    conda:
           "{}/workflow/envs/pandas.yml".format(workflow.basedir)
    input:
           syri = "07_syri_output/masked/{sample}/{sample}_clean.syri.out",
        assembly_IS_csv = "05_isescan_tables/{sample}.csv",
        ancestor_IS_csv = lambda wildcards: "05_isescan_tables/{}.csv".format(assembly_to_ancestor_dict[wildcards.sample]), # path to the csv file of the ancestor
        script = "{}/IS_SV_border.py".format(workflow.basedir)
    output:
        "11_annotated_boundaries/masked/{sample}_boundaries.csv"
    log:
        "logs/annotate_SV_boundaries_IS_masked/{sample}.log"
    shell:
        """
           mkdir -p 11_annotated_boundaries/masked
        cd 11_annotated_boundaries/masked
        {input.script} --ancestor ../../{input.ancestor_IS_csv} --evolved ../../{input.assembly_IS_csv} --syri ../../{input.syri} --output {wildcards.sample}_boundaries.csv > ../../{log} 2>&1
        cd ../../
        """

# annotate the mechanism of deletions and inversions
# i think you can expand and not wildcards here since the script does not have to be repeated each you run this..

rule annotate_SV_mechanism_unmasked:
    conda:
           "{}/workflow/envs/biopython.yml".format(workflow.basedir)
    input:
           boundaries_csv = expand("11_annotated_boundaries/unmasked/{sample}_boundaries.csv", sample=df['assembly'].tolist()),
        script = "{}/classify_deletions.py".format(workflow.basedir)
    output:
           inversion = expand("11_annotated_boundaries/unmasked/{sample}_inversion.csv",sample=df['assembly'].tolist()),
        deletion = expand("11_annotated_boundaries/unmasked/{sample}_deletion.csv",sample=df['assembly'].tolist()),
        inversion_table = "11_annotated_boundaries/unmasked/inversion_mechanism.csv",
        deletion_table = "11_annotated_boundaries/unmasked/deletion_mechanism.csv"
    params:
           input_dir = "11_annotated_boundaries/unmasked",
        output_deletion = "deletion_mechanism.csv",
        output_inversion = "inversion_mechanism.csv"
    log:
        "logs/annotate_SV_mechanism_unmasked/annotate_SV_mechanism.log"
    shell:
           """
           {input.script} --folder {params.input_dir} --output {params.output_inversion} --inversion > {log} 2>&1
        {input.script} --folder {params.input_dir} --output {params.output_deletion} --deletion >> {log} 2>&1
        cd ..
           """

rule annotate_SV_mechanism_masked:
    conda:
           "{}/workflow/envs/biopython.yml".format(workflow.basedir)
    input:
           boundaries_csv = expand("11_annotated_boundaries/masked/{sample}_boundaries.csv", sample=df['assembly'].tolist()),
        script = "{}/classify_deletions.py".format(workflow.basedir)
    output:
           inversion = expand("11_annotated_boundaries/masked/{sample}_inversion.csv",sample=df['assembly'].tolist()),
        deletion = expand("11_annotated_boundaries/masked/{sample}_deletion.csv",sample=df['assembly'].tolist()),
        inversion_table = "11_annotated_boundaries/masked/inversion_mechanism.csv",
        deletion_table = "11_annotated_boundaries/masked/deletion_mechanism.csv"
    params:
           input_dir = "11_annotated_boundaries/masked",
        output_deletion = "deletion_mechanism.csv",
        output_inversion = "inversion_mechanism.csv"
    log:
        "logs/annotate_SV_mechanism_masked/annotate_SV_mechanism.log"
    shell:
           """
           {input.script} --folder {params.input_dir} --output {params.output_inversion} --inversion > {log} 2>&1
        {input.script} --folder {params.input_dir} --output {params.output_deletion} --deletion >> {log} 2>&1
        cd ..
        """


# classify inversions as inter_replichore or intra-replichore

rule classify_inversion_replichore_unmasked:
    conda:
           "{}/workflow/envs/biopython.yml".format(workflow.basedir)
    input:
           ori_dif_coords = "04_rename_genome/ori_dif_coords.csv",
        inversion = expand("11_annotated_boundaries/unmasked/{sample}_inversion.csv",sample=df['assembly'].tolist()),
        #inversion = "11_annotated_boundaries/{sample}_inversion.csv",
        script = "{}/inversion_replichore_classify.py".format(workflow.basedir)
    output:
        expand("11_annotated_boundaries/unmasked/{sample}_inversion_classification.csv",sample=df['assembly'].tolist())
    params:
        input_dir = "11_annotated_boundaries/unmasked/",
        output_table = "inversion_replichores.csv",
        data=config['data']
    log:
        "logs/classify_inversion_replichore_unmasked/classify_inversion_replichore.log"
    shell:
        """
           {input.script} --folder {params.input_dir} --oridif {input.ori_dif_coords} --output {params.output_table} --data {params.data} > {log} 2>&1
        """

rule classify_inversion_replichore_masked:
    conda:
        "{}/workflow/envs/biopython.yml".format(workflow.basedir)
    input:
           ori_dif_coords = "04_rename_genome/ori_dif_coords.csv",
        inversion = expand("11_annotated_boundaries/masked/{sample}_inversion.csv",sample=df['assembly'].tolist()),
        script = "{}/inversion_replichore_classify.py".format(workflow.basedir)
    output:
        expand("11_annotated_boundaries/masked/{sample}_inversion_classification.csv",sample=df['assembly'].tolist())
    params:
           input_dir = "11_annotated_boundaries/masked/",
        output_table = "inversion_replichores.csv",
        data=config['data']
    log:
        "logs/classify_inversion_replichore_unmasked/classify_inversion_replichore.log"
    shell:
           """
           {input.script} --folder {params.input_dir} --oridif {input.ori_dif_coords} --output {params.output_table} --data {params.data} > {log} 2>&1
        """

# generate annotations for genomes using prokka and with the IS elements reported by ISEscan

rule annotate_genomes_prokka:
    conda:
        "{}/workflow/envs/prokka.yml".format(workflow.basedir)
    input:
        genome="04_rename_genome/unmasked/{sample}.fasta",
        is_table="05_isescan_tables/{sample}.csv"
    output:
        "09_annotated_genomes/{sample}/{sample}.gff"
    params:
        prefix="{sample}",
        outdir="09_annotated_genomes/{sample}",
        prokka_annotation="09_annotated_genomes/{sample}/{sample}.gff"
    log:
        "logs/annotate_genomes_prokka/{sample}.log"
    shell:
        """
        prokka --force --prefix {params.prefix} --outdir {params.outdir} {input.genome} > {log} 2>&1
        breseq CONVERT-REFERENCE -f GFF3 -s {input.is_table} -o {output} {params.prokka_annotation} >> {log} 2>&1
        """

# Use the clean_syri.out files to make the HTML tables from breseq
rule generate_genome_diffs_tables_unmasked:
    conda:
        "{}/workflow/envs/breseq.yml".format(workflow.basedir)
    input:
        syri = "07_syri_output/unmasked/{sample}/{sample}_clean.syri.out",
        script = "{}/syri2gd.py".format(workflow.basedir),
        reference = "09_annotated_genomes/{sample}/{sample}.gff"
    output:
        gd = "12_genome_diff_tables/gd/unmasked/{sample}.gd",
        html = "12_genome_diff_tables/html/unmasked/{sample}.html"
    params:
        gd_folder = "12_genome_diff_tables/gd/unmasked",
        html_folder = "12_genome_diff_tables/html/unmasked"
    log:
        "logs/generate_genome_diffs_tables_unmasked/{sample}.log"
    shell:
        """
        mkdir -p {params.gd_folder}
        mkdir -p {params.html_folder}
        cd {params.gd_folder}
        {input.script} --syri ../../../{input.syri} --output {wildcards.sample}.gd --deletion --inversion --amplification > ../../../{log} 2>&1
        cd ../../../{params.html_folder}
        gdtools ANNOTATE -o {wildcards.sample}.html -r ../../../{input.reference} -f HTML ../../../{output.gd} >> ../../../{log} 2>&1
        cd ../../../
        """

# Use the clean_syri.out files to make the HTML tables from breseq
rule generate_genome_diffs_tables_masked:
    conda:
        "{}/workflow/envs/breseq.yml".format(workflow.basedir)
    input:
        syri = "07_syri_output/masked/{sample}/{sample}_clean.syri.out",
        script = "{}/syri2gd.py".format(workflow.basedir),
        reference = "09_annotated_genomes/{sample}/{sample}.gff"
    output:
        gd = "12_genome_diff_tables/gd/masked/{sample}.gd",
        html = "12_genome_diff_tables/html/masked/{sample}.html"
    params:
        gd_folder = "12_genome_diff_tables/gd/masked",
        html_folder = "12_genome_diff_tables/html/masked"
    log:
        "logs/generate_genome_diffs_tables_masked/{sample}.log"
    shell:
        """
        mkdir -p {params.gd_folder}
        mkdir -p {params.html_folder}
        cd {params.gd_folder}
        {input.script} --syri ../../../{input.syri} --output {wildcards.sample}.gd --deletion --inversion --amplification > ../../../{log} 2>&1
        cd ../../../{params.html_folder}
        gdtools ANNOTATE -o {wildcards.sample}.html -r ../../../{input.reference} -f HTML ../../../{output.gd} >> ../../../{log} 2>&1
        cd ../../../
        """
